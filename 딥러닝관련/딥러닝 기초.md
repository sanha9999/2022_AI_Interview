## 텐서플로와 파이토치의 차이점은 무엇인가?

![참조](https://cdn.aitimes.com/news/photo/202010/132756_129974_5632.png)

## Supervised와 Unsupervised의 차이는 무엇일까?

Surpervised Learning은 지도 학습으로 정답을 알려주며 학습하는 것이다. label이 있는 data가 필요하다. Unsupervised Learning은 비지도 학습으로 정답을 따로 알려주지 않고 학습하는 것이다. 대표적으로 지도학습은 분류 + 회귀 문제에 많이 사용되고 비지도 학습은 군집화 문제에 사용된다.

## 강화학습이란 무엇인가?

상/벌을 주어 상을 최대화하고 벌을 최소화하는 값을 찾는 것을 학습하는 것이다. 대표적으로 그 유명한 알파고가 강화학습으로 학습되었다.

## 딥러닝은 무엇이고 머신러닝과 차이는 무엇인가?

딥러닝은 인공신경망을 깊은 구조로 설계하여 비선형성이 높은 문제들을 해결하는 방법을 통칭한다. 딥러닝은 머신러닝의 일종이며 모델 내부의 결정 과정을 해석하기 불가능한 **블랙박스**구조로 되어있다. 보통, 딥러닝이 일반적인 머신러닝 기법보다 더 많은 데이터를 필요로하며 계산량이 압도적으로 많다.

## 딥러닝의 장점과 단점

장점 : 비선형적으로 엮인 데이터로부터 특성추출에 강하다

단점 : 모델의 복잡도가 높다, ML모델에 비해 결과해석이 어렵다.

## 딥러닝에서 '표현을 학습하다'의 의미는 무엇인가?

머신러닝/딥러닝의 표현이란 데이터를 인코딩하거나 묘사하기 위해 데이터를 바라보는 다른 방법을 말한다.

## Cost Function과 Activation Function은 무엇인가?

Cost Function은 모델이 도출한 결과(output)와 목표 결과(target)를 어떻게 비교할 것인가를 의미한다. 두 결과의 차이를 의미하는 Cost는 Optimizer에 의해 Parameter가 갱신될 때, Step size를 얼마나 크게 가져갈 것인가에 결정적인 영향을 끼친다. Activation Function은 뉴런이 유입되는 신호로부터 도출하는 값을 정제하는 역할을 한다. Activation Function의 종류에는 sigmoid, Relu, Hyperbolic Tangent 등이 있다.

## Gradient Descent란?

Gradient Descent, 즉 경사 하강 알고리즘은 Cost Function(비용 함수)의 값을 최소화하는 파라미터를 찾는 알고리즘이다. 기본적인 개념은 함수의 기울기를 구하여 기울기가 낮은 쪽으로 계속 이동시켜 최적값에 이를 때까지 반복하는 것이다. Gradient Descent의 약점은 현재 위치에서의 기울기를 사용하기 때문에 local minimum에 빠질 수 있다는 점이다. 그래서 추후에 모멘텀이라는 방식이 등장하게 된다.

## Gradient Descent를 써야하는 이유는?

gradient를 통해 계산된 loss를 줄이기 위해, 역전파를 토대로 파라미터 값을 업데이트 하기 때문에 GD는 필수적으로 써야한다.

## Gradient Descent 종류에 대한 각각을 설명한다면?

![참조](https://www.dropbox.com/s/k03ffo5rjlwc03z/optimizers.png?raw=1)

## Local Minima와 Global Minima는 무엇인가?

Global minima는 Gradient Descent 방법으로 학습시에, 해당 도메인에 대해 가장 낮은 cost를 가질 수 있는 weight가 위치한 지점이다. Local Minima는 Gradient Descent로 Global Minima를 찾아가는 과정에서 주변에 지역적으로 Gradient 하강, 상승 구간이 존재하여 빠질 수 있는 가짜 Minima이다.

## Gradient Vanishing이란?

깊은 인공 신경망을 학습하다보면 역전파 과정에서 입력층으로 갈 수 록 기울기가 점차적으로 작아지는 현상이 발생하는데, 입력층에 가까운 층들에서 가중치가 제대로 업데이트되지 않으면 최적의 모델을 찾을 수 없다. 이를 기울기 소실(Gradient vanishing)이라고 한다.

## Gradient Exploding

기울기가 점차 커지더니 가중치들이 비정상적으로 큰 값이 되면서 발산되는 현상을 기울기 폭주(Gradient Exploding)라고 한다.

## Training 세트와 Test 세트를 분리하는 이유는?

실제 데이터에 대한 모델의 성능을 평가하기 위해, Training data로 사용했던 데이터를 모델의 평가에 활용하지 않는다.

## Test 세트가 오염되었다는 말은?

Test data에 Training data와 일치하거나, 매우 유사한 데이터들이 포함되어 Test data가 General한 상황에서의 성능 평가를 수행하지 못함을 말한다.

## Validation 세트가 따로 있는 이유는?

모델 학습 과정 중, Training data와 분리된 Validation data로 모델을 평가하여 그 결과를 학습에 반영하므로써 Training Data에 대한 Overfitting을 방지하는 효과가 있다.

## Overfitting이란?
훈련 데이터에 대한 정확도는 높을지라도, 새로운 데이터(ex 검증 데이터나 테스트 데이터)에서는 제대로 동작하지 않는다.

## Overfitting을 확인하는 방법은?
Train set에 대한 모델의 성능과 test set에 대한 모델의 성능을 비교하여 test set에 대한 성능이 train set보다 훨씬 낮게 나온다면 overfitting이 나온다고 판단할 수 있다.

## Overfitting(과적합) 피하기

- 모델을 간단하게 만들기 (파라미터 수 줄이기)
- k-fold cross validation
- 데이터의 양을 늘리기(Data Augmentation)
- 정규화를 사용한다.